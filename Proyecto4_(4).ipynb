{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install livelossplot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1KN3KfmS7cK",
        "outputId": "d954c279-820a-43fb-b8f2-59afd36a8680"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: livelossplot in /usr/local/lib/python3.7/dist-packages (0.5.5)\n",
            "Requirement already satisfied: numpy<1.22 in /usr/local/lib/python3.7/dist-packages (from livelossplot) (1.21.6)\n",
            "Requirement already satisfied: ipython==7.* in /usr/local/lib/python3.7/dist-packages (from livelossplot) (7.9.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from livelossplot) (3.2.2)\n",
            "Requirement already satisfied: bokeh in /usr/local/lib/python3.7/dist-packages (from livelossplot) (2.3.3)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (0.2.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (2.6.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (5.1.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (4.4.2)\n",
            "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (0.18.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (57.4.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (2.0.10)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython==7.*->livelossplot) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython==7.*->livelossplot) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython==7.*->livelossplot) (1.15.0)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (6.0.4)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (2.11.3)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (4.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (2.8.2)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (21.3)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.9->bokeh->livelossplot) (2.0.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=16.8->bokeh->livelossplot) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->livelossplot) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->livelossplot) (0.11.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython==7.*->livelossplot) (0.7.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6yhkP9WGoGz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Rh_QnX9Q2ux"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from glob import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset, SubsetRandomSampler\n",
        "from torchvision.transforms import ToTensor, Lambda\n",
        "from tqdm import tqdm\n",
        "from livelossplot import PlotLosses"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TVMXTr0oJn5",
        "outputId": "7c4aed1b-fe39-41a7-b189-bc3b6ae1dc56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fbb8649fa10>"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5r965e8lQ2u2",
        "outputId": "d0453037-836e-4495-a192-7102ca98fceb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "\n",
            "Tesla T4\n",
            "Memory Usage:\n",
            "Allocated: 0.1 GB\n",
            "Cached:    7.8 GB\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "print()\n",
        "\n",
        "#Additional Info when using cuda\n",
        "if device.type == 'cuda':\n",
        "    print(torch.cuda.get_device_name(0))\n",
        "    print('Memory Usage:')\n",
        "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
        "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cy249X_aTNED",
        "outputId": "8910a2d5-9fa3-43ad-8066-938a7c1ca91d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "with ZipFile('/content/drive/MyDrive/COVID-19_Radiography_Dataset.zip', 'r') as f:\n",
        "  f.extractall()"
      ],
      "metadata": {
        "id": "EMhrXTTFTdOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OIX3hwaIQ2u4"
      },
      "outputs": [],
      "source": [
        "label_map ={\n",
        "    0 : \"Normal\",\n",
        "    1 : \"Covid\",\n",
        "    2 : \"Lung_Opacity\",\n",
        "    3 : \"Viral Pneumonia\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFW0Zr6TQ2u4",
        "outputId": "01d5a3cf-ae80-4be7-bde3-5a20f15cabd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Images:  21165 , Labels:  21165 , Masks:  21165\n"
          ]
        }
      ],
      "source": [
        "masks_pwd = [\"COVID-19_Radiography_Dataset/Normal/masks/*\",\"COVID-19_Radiography_Dataset/COVID/masks/*\", \n",
        "\"COVID-19_Radiography_Dataset/Lung_Opacity/masks/*\",\"COVID-19_Radiography_Dataset/Viral Pneumonia/masks/*\"]\n",
        "images_pwd = [\"COVID-19_Radiography_Dataset/Normal/images/*\",\"COVID-19_Radiography_Dataset/COVID/images/*\", \n",
        "\"COVID-19_Radiography_Dataset/Lung_Opacity/images/*\",\"COVID-19_Radiography_Dataset/Viral Pneumonia/images/*\"]\n",
        "image_paths = []\n",
        "labels = []\n",
        "mask_paths = []\n",
        "for i, (folder_img_path, folder_mask_path) in enumerate(zip(images_pwd, masks_pwd)):\n",
        "    for f_path, m_path in zip(glob(folder_img_path), glob(folder_mask_path)):\n",
        "        image_paths.append(f_path)\n",
        "        mask_paths.append(m_path)\n",
        "        labels.append(i)\n",
        "\n",
        "print(\"Images: \", len(image_paths), \", Labels: \", len(labels), \", Masks: \" ,len(mask_paths))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5NgJe1KaQ2u5"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([transforms.ToTensor()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQsYN3QKQ2u6"
      },
      "outputs": [],
      "source": [
        "class PulmonesDataset:\n",
        "    def __init__(self, img_paths, img_labels):\n",
        "        self.img_paths = img_paths\n",
        "        self.img_labels = img_labels\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        PULMON_IMAGE = Image.open(self.img_paths[index]).convert('L') # Convierte gray-scale\n",
        "        TENSOR_IMAGE = transform(PULMON_IMAGE)\n",
        "        label = self.img_labels[index]\n",
        "        return TENSOR_IMAGE, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFOFkDWTQ2u7"
      },
      "outputs": [],
      "source": [
        "pulmon = Image.open(\"COVID-19_Radiography_Dataset/Normal/images/Normal-1.png\").convert('L')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NO_aScPRQ2u8"
      },
      "outputs": [],
      "source": [
        "dataset = PulmonesDataset(image_paths, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ioc4BKGuQ2u8",
        "outputId": "779fd029-b470-44b2-f896-c0063723134b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training examples: 14815\n",
            "Number of validation examples: 4254\n",
            "Number of test examples: 2096\n"
          ]
        }
      ],
      "source": [
        "dataset_indices = list(range(0, len(dataset)))\n",
        "dataset_labels = labels\n",
        "train_indices, test_indices = train_test_split(dataset_indices, test_size=0.3, random_state = 1, stratify= dataset_labels )\n",
        "\n",
        "test_labels = [dataset_labels[idx] for idx in test_indices]\n",
        "validate_indices, test_indices = train_test_split(test_indices, test_size = 0.33, random_state = 1, stratify= test_labels)\n",
        "print(f\"Number of training examples: {len(train_indices)}\")\n",
        "print(f\"Number of validation examples: {len(validate_indices)}\")\n",
        "print(f\"Number of test examples: {len(test_indices)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wEfhr1grQ2u9"
      },
      "outputs": [],
      "source": [
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "validation_sampler = SubsetRandomSampler(validate_indices)\n",
        "test_sampler = SubsetRandomSampler(test_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYRVaB8IQ2u-",
        "outputId": "58bcc497-b9d0-4fae-eda6-c57fa80b2b16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14815\n",
            "4254\n",
            "2096\n"
          ]
        }
      ],
      "source": [
        "print(len(train_sampler))\n",
        "print(len(validation_sampler))\n",
        "print(len(test_sampler))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXR11128Q2u-"
      },
      "source": [
        "# Preparing Data Loader Objects"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mdZy5P8rQ2vA",
        "outputId": "bb802e4b-9555-401a-81b0-498303257c4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-df87bed01295>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_sampler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mvalidation_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_sampler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtest_sampler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'DataLoader' is not defined"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 8\n",
        "train_loader = DataLoader(dataset, batch_size= BATCH_SIZE, sampler=train_sampler)\n",
        "validation_loader = DataLoader(dataset, batch_size=BATCH_SIZE, sampler=validation_sampler)\n",
        "test_loader = DataLoader(dataset, batch_size=BATCH_SIZE, sampler= test_sampler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1ps1HXEQ2vA"
      },
      "outputs": [],
      "source": [
        "print(len(train_loader))\n",
        "print(len(validation_loader))\n",
        "print(len(test_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VRCfEZBcQ2vB"
      },
      "outputs": [],
      "source": [
        "images, labels = next(iter(train_loader))\n",
        "type(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAI6LJIAQ2vB"
      },
      "outputs": [],
      "source": [
        "images, labels = next(iter(train_loader))\n",
        "fig, axis= plt.subplots(4, 6, figsize=(15, 18))\n",
        "for i, ax in enumerate(axis.flat):\n",
        "    with torch.no_grad():\n",
        "        npimg = images[i].numpy()\n",
        "        npimg = np.transpose(npimg, (1, 2, 0))\n",
        "        npimg = np.reshape(npimg, (299,299))\n",
        "        label = label_map[int(labels[i])]\n",
        "        ax.imshow(npimg)\n",
        "        ax.set(title=f\"{label}\")\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwIgdDgPQ2vB"
      },
      "outputs": [],
      "source": [
        "def get_composition(index_lst: list, test_name = \"generic\"):\n",
        "    counter = {}\n",
        "    for label in label_map:\n",
        "        counter[label_map[label]] = 0\n",
        "\n",
        "    for inx in index_lst:\n",
        "        label = dataset_labels[inx]\n",
        "        counter[label_map[label] ] += 1\n",
        "\n",
        "    return pd.DataFrame.from_dict(counter, orient= 'index', columns= [test_name]) / len(index_lst)\n",
        "\n",
        "\n",
        "distSet = [ (train_indices, \"train\"), (validate_indices,\"validate\") , (test_indices,\"test\")]\n",
        "df_lst = [ get_composition(idx, name) for idx, name in distSet]\n",
        "df_dst = pd.concat( df_lst, axis = 1) \n",
        "\n",
        "df_dst "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BRVrsPdpQ2vC"
      },
      "outputs": [],
      "source": [
        "num_classes = 4\n",
        "learning_rate = 0.001\n",
        "num_epochs = 20"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms, models"
      ],
      "metadata": {
        "id": "cBvSFN1F1I_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n"
      ],
      "metadata": {
        "id": "h8UNaIJj1OK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN5(nn.Module):\n",
        "    def __init__(self, num_classes = 4):\n",
        "        super(CNN5, self).__init__()\n",
        "        self.flatten = nn.Flatten() # Reduce cualquier matriz a 1D\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=2),# 256 -> 258 (mask) 299 -> 301\n",
        "            nn.Dropout(p=0.25),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2), # 129 | 150\n",
        "            nn.BatchNorm2d(16)\n",
        "        )\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2), # 129 -> 129 (mask) | 150-> 150\n",
        "            nn.Dropout(p=0.25),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2), # 129 // 2 = 64 (mask) | 75\n",
        "            nn.BatchNorm2d(32)\n",
        "\n",
        "        )\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, kernel_size= 3, stride= 1, padding=1), # 64 -> 64 | 75 -> 75\n",
        "            nn.Dropout(p=0.25),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2), # 64 // 2 -> 32 || 75 // 2 -> 37\n",
        "            nn.BatchNorm2d(64)\n",
        "        )\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size= 3, stride=1, padding=1), # 32 -> 32\n",
        "            nn.Dropout(p=0.25),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2), # 16 -> 16\n",
        "            nn.BatchNorm2d(128)\n",
        "        )\n",
        "        self.fc = nn.Linear(18*18*128, 128 ) \n",
        "        self.act = nn.Sigmoid()\n",
        "        self.fc2 = nn.Linear(128, num_classes) \n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        out = self.act(out)\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "HK-GVwOkPtPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UtgDDOqcQ2vC"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, num_classes = 4):\n",
        "        super(CNN, self).__init__()\n",
        "        self.den = models.densenet121(pretrained=False)\n",
        "        self.features = nn.Sequential(\n",
        "    nn.Sequential(OrderedDict([\n",
        "            ('conv0', nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1, bias=False)),\n",
        "            ('norm0', nn.BatchNorm2d(64)),\n",
        "            ('relu0', nn.ReLU(inplace=True))\n",
        "        ])), self.den.features[4:])\n",
        "        self.classifier = nn.Sequential(\n",
        "    nn.Linear(1024, 512),\n",
        "    nn.Dropout(p=0.1),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(512, 4)\n",
        ")\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.den(x)\n",
        "        out = self.features(out)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        out = self.classifier(out)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net = models.densenet121(pretrained=False)\n",
        "net.features = nn.Sequential(\n",
        "    nn.Sequential(OrderedDict([\n",
        "            ('conv0', nn.Conv2d(1, 64, kernel_size=3, stride=2, padding=1, bias=False)),\n",
        "            ('norm0', nn.BatchNorm2d(64)),\n",
        "            ('relu0', nn.ReLU(inplace=True))\n",
        "        ])),  # 96**2 -> 48**2\n",
        "    net.features[4:])\n",
        "\n",
        "net.classifier = nn.Sequential(\n",
        "    nn.Linear(1024, 512),\n",
        "    nn.Dropout(p=0.1),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(512, 4)\n",
        ")"
      ],
      "metadata": {
        "id": "ntQyPY5H2n92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crKfuAI3Q2vD"
      },
      "outputs": [],
      "source": [
        "def showLoss(loss, val, mensaje = \"Loss\", valmsg = \"Validation\"):\n",
        "    plt.subplots(figsize=(6, 4))\n",
        "    plt.plot(range(len(loss)), loss, color=\"blue\", label=mensaje)\n",
        "    plt.plot(range(len(val)), val, color=\"orange\", label=valmsg)\n",
        "    plt.legend()\n",
        "    plt.draw()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tnJ2oRv3Q2vD"
      },
      "outputs": [],
      "source": [
        "def getAccuracy(model, loader):\n",
        "    with torch.no_grad():\n",
        "      correct = 0\n",
        "      total = 0\n",
        "      for images, labels in loader:\n",
        "          images = images.to(device)\n",
        "          labels = labels.to(device)\n",
        "          outputs = model(images)\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "      return 100 * correct / total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dgIy4oA5Q2vD"
      },
      "outputs": [],
      "source": [
        "model = CNN5(4).to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "            path (str): Path for the checkpoint to be saved to.\n",
        "                            Default: 'checkpoint.pt'\n",
        "            trace_func (function): trace print function.\n",
        "                            Default: print            \n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "        self.trace_func = trace_func\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        self.val_loss_min = val_loss"
      ],
      "metadata": {
        "id": "Hmd9XGswtj4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QoAxMXD4Q2vE"
      },
      "outputs": [],
      "source": [
        "def train(model, optimizer, loss_fn, num_epochs, patience = 3):\n",
        "  # train the model\n",
        "  liveplot= PlotLosses()\n",
        "  loss_lst = []\n",
        "  val_loss_lst = []\n",
        "  early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
        "\n",
        "  for epoch in tqdm(range(num_epochs), desc = \"Training model...\"):\n",
        "    logs = {}\n",
        "    epoch_total = 0.\n",
        "    validation_total = 0.\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "      # forward \n",
        "      output = model(images)\n",
        "      loss   = loss_fn(output, labels)\n",
        "      # change the params\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      epoch_total += loss.item()\n",
        "      \n",
        "    with torch.set_grad_enabled(False):\n",
        "      for i, (images, labels) in enumerate(validation_loader):\n",
        "        # Transfer to GPU\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        # forward \n",
        "        output = model(images)\n",
        "        loss   = loss_fn(output, labels)\n",
        "\n",
        "        validation_total += loss.item()\n",
        "        \n",
        "    loss = epoch_total / len(train_loader)\n",
        "    val_loss = validation_total /  len(validation_loader)\n",
        "    logs[\"loss\"] , logs[\"val_loss\"] = loss, val_loss\n",
        "    logs[\"accuracy\"] = getAccuracy(model, train_loader)\n",
        "    logs[\"val_accuracy\"] = getAccuracy(model, validation_loader)\n",
        "    loss_lst.append(loss)\n",
        "    val_loss_lst.append(val_loss)\n",
        "\n",
        "    liveplot.update(logs)\n",
        "    liveplot.send()\n",
        "\n",
        "    early_stopping(val_loss = val_loss, model = model)\n",
        "    if early_stopping.early_stop:\n",
        "      print(\"Early stopping\")\n",
        "      break\n",
        "\n",
        "  model.load_state_dict(torch.load('checkpoint.pt'))            \n",
        "  return model, loss_lst, val_loss_lst"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "scLMc5h4Q2vE"
      },
      "outputs": [],
      "source": [
        "\n",
        "model_result, loss_result, val_loss_result = train(model, optimizer, loss_fn, num_epochs = 20)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc_val, acc_test = getAccuracy(model_result, validation_loader) , getAccuracy(model_result, test_loader)\n",
        "print(f\"Validation Accuracy of: {acc_val}\", f\"Test Accuracy of: {acc_test }\")"
      ],
      "metadata": {
        "id": "mpMS8KULzmiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def showEarly(train_loss, valid_loss):\n",
        "    # visualize the loss as the network trained\n",
        "    fig = plt.figure(figsize=(10,8))\n",
        "    plt.plot(range(1,len(train_loss)+1),train_loss, label='Training Loss')\n",
        "    plt.plot(range(1,len(valid_loss)+1),valid_loss,label='Validation Loss')\n",
        "\n",
        "    # find position of lowest validation loss\n",
        "    minposs = valid_loss.index(min(valid_loss))+1 \n",
        "    plt.axvline(minposs, linestyle='--', color='r',label='Early Stopping Checkpoint')\n",
        "\n",
        "    plt.xlabel('epochs')\n",
        "    plt.ylabel('loss')\n",
        "    plt.ylim(0, max(max(train_loss), max(valid_loss)) ) # consistent scale\n",
        "    plt.xlim(0, len(train_loss)+1) # consistent scale\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    fig.savefig('loss_plot.png', bbox_inches='tight')"
      ],
      "metadata": {
        "id": "z8HxSiwXY2LN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "showEarly(loss_result, val_loss_result)"
      ],
      "metadata": {
        "id": "iaZRW6rcY5sV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EnEL9pJMQ2vE"
      },
      "outputs": [],
      "source": [
        "print(\"Validation\")\n",
        "getAccuracy(model, validation_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OwL3Em2PQ2vF"
      },
      "outputs": [],
      "source": [
        "print(\"Test\")\n",
        "getAccuracy(model, test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyHFwEv8Q2vF"
      },
      "source": [
        "# Agregar una capa adicional"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50_Dh0KkQ2vF"
      },
      "outputs": [],
      "source": [
        "class CNN1(nn.Module):\n",
        "    def __init__(self, num_classes = 4):\n",
        "        super(CNN1, self).__init__()\n",
        "        self.flatten = nn.Flatten() # Reduce cualquier matriz a 1D\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=2),# 256 -> 258 (mask) 299 -> 301\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2) # 129 | 150\n",
        "        )\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2), # 129 -> 129 (mask) | 150-> 150\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2) # 129 // 2 = 64 (mask) | 75\n",
        "        )\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, kernel_size= 3, stride= 1, padding=1), # 64 -> 64 | 75 -> 75\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2) # 64 // 2 -> 32 || 75 // 2 -> 37\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Linear(32*32*64, num_classes) # 32 * 32 * 32 (mask) | 37 * 37 * 64\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I66HmXSiQ2vF",
        "outputId": "0e7a5a01-ec8e-4899-cdbc-1d8d63301082"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[torch.Size([4, 65536]), torch.Size([4])]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 1.6638e-03,  2.9210e-03, -2.6541e-03,  ..., -6.6661e-04,\n",
              "         -6.4705e-04,  2.5629e-03],\n",
              "        [-1.6599e-03, -2.9030e-03, -6.0821e-04,  ..., -9.5855e-04,\n",
              "         -2.0415e-03, -1.0899e-03],\n",
              "        [ 3.7865e-03,  3.4328e-03,  2.1990e-03,  ...,  3.8254e-03,\n",
              "          2.8717e-03, -2.1679e-04],\n",
              "        [-3.2991e-03,  5.6185e-05, -1.2430e-03,  ..., -3.7531e-03,\n",
              "         -1.3773e-03, -3.4612e-03]], device='cuda:0', requires_grad=True)"
            ]
          },
          "execution_count": 146,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model1 = CNN1(num_classes).to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model1.parameters(), lr=learning_rate)\n",
        "print([ e.shape  for e in model1.fc.parameters()])\n",
        "model1.fc.weight\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BqhKXqJ_Q2vG",
        "outputId": "f1c1f3ef-234b-4565-f1c1-b77f910ccee2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/20], Step [100/463], Loss: 1.1090\n",
            "Epoch [1/20], Step [200/463], Loss: 0.9085\n",
            "Epoch [1/20], Step [300/463], Loss: 0.7866\n",
            "Epoch [1/20], Step [400/463], Loss: 0.9533\n",
            "Epoch [2/20], Step [100/463], Loss: 1.0763\n",
            "Epoch [2/20], Step [200/463], Loss: 0.9757\n",
            "Epoch [2/20], Step [300/463], Loss: 0.7258\n",
            "Epoch [2/20], Step [400/463], Loss: 0.8709\n",
            "Epoch [3/20], Step [100/463], Loss: 0.4516\n",
            "Epoch [3/20], Step [200/463], Loss: 0.5758\n",
            "Epoch [3/20], Step [300/463], Loss: 0.7123\n",
            "Epoch [3/20], Step [400/463], Loss: 0.5658\n",
            "Epoch [4/20], Step [100/463], Loss: 0.4859\n",
            "Epoch [4/20], Step [200/463], Loss: 0.7554\n",
            "Epoch [4/20], Step [300/463], Loss: 0.8973\n",
            "Epoch [4/20], Step [400/463], Loss: 0.5337\n",
            "Epoch [5/20], Step [100/463], Loss: 0.6448\n",
            "Epoch [5/20], Step [200/463], Loss: 0.5963\n",
            "Epoch [5/20], Step [300/463], Loss: 0.8689\n",
            "Epoch [5/20], Step [400/463], Loss: 0.7573\n",
            "Epoch [6/20], Step [100/463], Loss: 0.5443\n",
            "Epoch [6/20], Step [200/463], Loss: 0.4414\n",
            "Epoch [6/20], Step [300/463], Loss: 0.4296\n",
            "Epoch [6/20], Step [400/463], Loss: 0.3454\n",
            "Epoch [7/20], Step [100/463], Loss: 0.3187\n",
            "Epoch [7/20], Step [200/463], Loss: 0.6434\n",
            "Epoch [7/20], Step [300/463], Loss: 0.3291\n",
            "Epoch [7/20], Step [400/463], Loss: 0.4491\n",
            "Epoch [8/20], Step [100/463], Loss: 0.5030\n",
            "Epoch [8/20], Step [200/463], Loss: 0.3843\n",
            "Epoch [8/20], Step [300/463], Loss: 0.3948\n",
            "Epoch [8/20], Step [400/463], Loss: 0.5700\n",
            "Epoch [9/20], Step [100/463], Loss: 0.5670\n",
            "Epoch [9/20], Step [200/463], Loss: 0.1919\n",
            "Epoch [9/20], Step [300/463], Loss: 0.4575\n",
            "Epoch [9/20], Step [400/463], Loss: 0.1753\n",
            "Epoch [10/20], Step [100/463], Loss: 0.3863\n",
            "Epoch [10/20], Step [200/463], Loss: 0.4625\n",
            "Epoch [10/20], Step [300/463], Loss: 0.2518\n",
            "Epoch [10/20], Step [400/463], Loss: 0.2694\n",
            "Epoch [11/20], Step [100/463], Loss: 0.2643\n",
            "Epoch [11/20], Step [200/463], Loss: 0.1508\n",
            "Epoch [11/20], Step [300/463], Loss: 0.1645\n",
            "Epoch [11/20], Step [400/463], Loss: 0.1825\n",
            "Epoch [12/20], Step [100/463], Loss: 0.1445\n",
            "Epoch [12/20], Step [200/463], Loss: 0.0850\n",
            "Epoch [12/20], Step [300/463], Loss: 0.4096\n",
            "Epoch [12/20], Step [400/463], Loss: 0.1808\n",
            "Epoch [13/20], Step [100/463], Loss: 0.1764\n",
            "Epoch [13/20], Step [200/463], Loss: 0.1409\n",
            "Epoch [13/20], Step [300/463], Loss: 0.1771\n",
            "Epoch [13/20], Step [400/463], Loss: 0.1105\n",
            "Epoch [14/20], Step [100/463], Loss: 0.0542\n",
            "Epoch [14/20], Step [200/463], Loss: 0.1542\n",
            "Epoch [14/20], Step [300/463], Loss: 0.3160\n",
            "Epoch [14/20], Step [400/463], Loss: 0.1507\n",
            "Epoch [15/20], Step [100/463], Loss: 0.0223\n",
            "Epoch [15/20], Step [200/463], Loss: 0.1291\n",
            "Epoch [15/20], Step [300/463], Loss: 0.0678\n",
            "Epoch [15/20], Step [400/463], Loss: 0.2515\n",
            "Epoch [16/20], Step [100/463], Loss: 0.1203\n",
            "Epoch [16/20], Step [200/463], Loss: 0.0849\n",
            "Epoch [16/20], Step [300/463], Loss: 0.0211\n",
            "Epoch [16/20], Step [400/463], Loss: 0.1062\n",
            "Epoch [17/20], Step [100/463], Loss: 0.0095\n",
            "Epoch [17/20], Step [200/463], Loss: 0.0110\n",
            "Epoch [17/20], Step [300/463], Loss: 0.0255\n",
            "Epoch [17/20], Step [400/463], Loss: 0.1597\n",
            "Epoch [18/20], Step [100/463], Loss: 0.0175\n",
            "Epoch [18/20], Step [200/463], Loss: 0.0182\n",
            "Epoch [18/20], Step [300/463], Loss: 0.0761\n",
            "Epoch [18/20], Step [400/463], Loss: 0.0066\n",
            "Epoch [19/20], Step [100/463], Loss: 0.0197\n",
            "Epoch [19/20], Step [200/463], Loss: 0.1353\n",
            "Epoch [19/20], Step [300/463], Loss: 0.0238\n",
            "Epoch [19/20], Step [400/463], Loss: 0.0292\n",
            "Epoch [20/20], Step [100/463], Loss: 0.0665\n",
            "Epoch [20/20], Step [200/463], Loss: 0.0337\n",
            "Epoch [20/20], Step [300/463], Loss: 0.0583\n",
            "Epoch [20/20], Step [400/463], Loss: 0.1083\n",
            "Finished Training Trainset\n"
          ]
        }
      ],
      "source": [
        "list_loss = train(model1, optimizer, loss_fn, 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6Jrop15Q2vG",
        "outputId": "4376f6e1-0b7b-42da-faa2-0aa0fdaee5ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation\n",
            "Test Accuracy of the model: 65.5618241654913 %\n"
          ]
        }
      ],
      "source": [
        "print(\"Validation\")\n",
        "getAccuracy(model1, validation_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tsChqDBRQ2vG",
        "outputId": "ad84822a-3955-4222-c95c-86a08503d794"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test\n",
            "Test Accuracy of the model: 64.79007633587786 %\n"
          ]
        }
      ],
      "source": [
        "print(\"Test\")\n",
        "getAccuracy(model1, test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1R0IbhJXQ2vG"
      },
      "source": [
        "# Agregar dos capas adicionales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_m5OGZHpQ2vH"
      },
      "outputs": [],
      "source": [
        "class CNN2(nn.Module):\n",
        "    def __init__(self, num_classes = 4):\n",
        "        super(CNN2, self).__init__()\n",
        "        self.flatten = nn.Flatten() # Reduce cualquier matriz a 1D\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=2),# 256 -> 258 (mask) 299 -> 301\n",
        "            nn.Dropout(p = 0.25),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2), # 129 | 150\n",
        "            nn.BatchNorm2d(16)\n",
        "        )\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2), # 129 -> 129 (mask) | 150-> 150\n",
        "            nn.Dropout(p = 0.25),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2), # 129 // 2 = 64 (mask) | 75\n",
        "            nn.BatchNorm2d(32)\n",
        "        )\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, kernel_size= 3, stride= 1, padding=1), # 64 -> 64 | 75 -> 75\n",
        "            nn.Dropout(p = 0.25),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2), # 64 // 2 -> 32 || 75 // 2 -> 37\n",
        "            nn.BatchNorm2d(64)\n",
        "        )\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size= 3, stride=1, padding=1), # 32 -> 32\n",
        "            nn.Dropout(p = 0.25),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2), # 16 -> 16\n",
        "            nn.BatchNorm2d(128)\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Linear(18*18*128, num_classes) # 32 * 32 * 32 (mask) | 18 * 18 * 128\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOiDlEaSQ2vH"
      },
      "source": [
        "## Agregando batch normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3pihcMZzQ2vH"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(50)\n",
        "class CNN3(nn.Module):\n",
        "    def __init__(self, num_classes = 4):\n",
        "        super(CNN3, self).__init__()\n",
        "        self.flatten = nn.Flatten() # Reduce cualquier matriz a 1D\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=2),# 256 -> 258 (mask) 299 -> 301\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2), # 129 | 150\n",
        "            nn.BatchNorm2d(16)\n",
        "        )\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2), # 129 -> 129 (mask) | 150-> 150\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),# 129 // 2 = 64 (mask) | 75\n",
        "            nn.BatchNorm2d(32)\n",
        "        )\n",
        "        self.fc = nn.Linear(75*75*32, num_classes) # 64 * 64 * 32 (mask) | 75 * 75 * 32\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apTT3KUxQ2vH",
        "outputId": "eaf1d8aa-4c90-4c4c-fe93-4fec59983dd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[torch.Size([4, 180000]), torch.Size([4])]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 0.0007,  0.0011,  0.0010,  ..., -0.0022, -0.0010,  0.0019],\n",
              "        [ 0.0012,  0.0002, -0.0013,  ..., -0.0015, -0.0016, -0.0009],\n",
              "        [ 0.0014,  0.0023,  0.0001,  ...,  0.0020,  0.0009,  0.0014],\n",
              "        [-0.0018, -0.0005,  0.0022,  ...,  0.0016,  0.0022,  0.0017]],\n",
              "       device='cuda:0', requires_grad=True)"
            ]
          },
          "execution_count": 185,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "network3 = CNN3(num_classes=num_classes).to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(network3.parameters(), lr=learning_rate)\n",
        "print([ e.shape  for e in network3.fc.parameters()])\n",
        "network3.fc.weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDTtH1ufQ2vI",
        "outputId": "de7e0c3c-2716-4fff-be4e-1d0006006753"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/20], Step [100/463], Loss: 9.1941\n",
            "Epoch [1/20], Step [200/463], Loss: 2.2015\n",
            "Epoch [1/20], Step [300/463], Loss: 0.3813\n",
            "Epoch [1/20], Step [400/463], Loss: 3.4633\n",
            "Epoch [2/20], Step [100/463], Loss: 3.9101\n",
            "Epoch [2/20], Step [200/463], Loss: 1.2899\n",
            "Epoch [2/20], Step [300/463], Loss: 1.6355\n",
            "Epoch [2/20], Step [400/463], Loss: 1.0140\n",
            "Epoch [3/20], Step [100/463], Loss: 0.2367\n",
            "Epoch [3/20], Step [200/463], Loss: 0.2914\n",
            "Epoch [3/20], Step [300/463], Loss: 0.2021\n",
            "Epoch [3/20], Step [400/463], Loss: 0.7075\n",
            "Epoch [4/20], Step [100/463], Loss: 0.0856\n",
            "Epoch [4/20], Step [200/463], Loss: 0.2142\n",
            "Epoch [4/20], Step [300/463], Loss: 0.7762\n",
            "Epoch [4/20], Step [400/463], Loss: 0.2428\n",
            "Epoch [5/20], Step [100/463], Loss: 0.0271\n",
            "Epoch [5/20], Step [200/463], Loss: 0.5581\n",
            "Epoch [5/20], Step [300/463], Loss: 0.0002\n",
            "Epoch [5/20], Step [400/463], Loss: 1.0190\n",
            "Epoch [6/20], Step [100/463], Loss: 0.1700\n",
            "Epoch [6/20], Step [200/463], Loss: 0.0004\n",
            "Epoch [6/20], Step [300/463], Loss: 0.2338\n",
            "Epoch [6/20], Step [400/463], Loss: 0.2514\n",
            "Epoch [7/20], Step [100/463], Loss: 0.3524\n",
            "Epoch [7/20], Step [200/463], Loss: 0.0004\n",
            "Epoch [7/20], Step [300/463], Loss: 0.0751\n",
            "Epoch [7/20], Step [400/463], Loss: 0.0028\n",
            "Epoch [8/20], Step [100/463], Loss: 1.3919\n",
            "Epoch [8/20], Step [200/463], Loss: 0.0170\n",
            "Epoch [8/20], Step [300/463], Loss: 0.3124\n",
            "Epoch [8/20], Step [400/463], Loss: 0.0300\n",
            "Epoch [9/20], Step [100/463], Loss: 0.3952\n",
            "Epoch [9/20], Step [200/463], Loss: 0.1903\n",
            "Epoch [9/20], Step [300/463], Loss: 0.1284\n",
            "Epoch [9/20], Step [400/463], Loss: 0.0091\n",
            "Epoch [10/20], Step [100/463], Loss: 0.0000\n",
            "Epoch [10/20], Step [200/463], Loss: 0.2675\n",
            "Epoch [10/20], Step [300/463], Loss: 0.0000\n",
            "Epoch [10/20], Step [400/463], Loss: 0.3505\n",
            "Epoch [11/20], Step [100/463], Loss: 0.0018\n",
            "Epoch [11/20], Step [200/463], Loss: 0.0000\n",
            "Epoch [11/20], Step [300/463], Loss: 0.0167\n",
            "Epoch [11/20], Step [400/463], Loss: 0.0011\n",
            "Epoch [12/20], Step [100/463], Loss: 0.0000\n",
            "Epoch [12/20], Step [200/463], Loss: 0.0022\n",
            "Epoch [12/20], Step [300/463], Loss: 0.0869\n",
            "Epoch [12/20], Step [400/463], Loss: 0.0748\n",
            "Epoch [13/20], Step [100/463], Loss: 0.0001\n",
            "Epoch [13/20], Step [200/463], Loss: 0.0002\n",
            "Epoch [13/20], Step [300/463], Loss: 0.1746\n",
            "Epoch [13/20], Step [400/463], Loss: 0.0000\n",
            "Epoch [14/20], Step [100/463], Loss: 0.0377\n",
            "Epoch [14/20], Step [200/463], Loss: 0.2953\n",
            "Epoch [14/20], Step [300/463], Loss: 0.0005\n",
            "Epoch [14/20], Step [400/463], Loss: 0.0000\n",
            "Epoch [15/20], Step [100/463], Loss: 0.0000\n",
            "Epoch [15/20], Step [200/463], Loss: 0.0012\n",
            "Epoch [15/20], Step [300/463], Loss: 0.0005\n",
            "Epoch [15/20], Step [400/463], Loss: 0.0362\n",
            "Epoch [16/20], Step [100/463], Loss: 0.0001\n",
            "Epoch [16/20], Step [200/463], Loss: 0.0000\n",
            "Epoch [16/20], Step [300/463], Loss: 0.0024\n",
            "Epoch [16/20], Step [400/463], Loss: 0.0240\n",
            "Epoch [17/20], Step [100/463], Loss: 0.0668\n",
            "Epoch [17/20], Step [200/463], Loss: 0.0081\n",
            "Epoch [17/20], Step [300/463], Loss: 0.0106\n",
            "Epoch [17/20], Step [400/463], Loss: 0.0000\n",
            "Epoch [18/20], Step [100/463], Loss: 0.0020\n",
            "Epoch [18/20], Step [200/463], Loss: 0.0013\n",
            "Epoch [18/20], Step [300/463], Loss: 0.0065\n",
            "Epoch [18/20], Step [400/463], Loss: 0.4942\n",
            "Epoch [19/20], Step [100/463], Loss: 0.0001\n",
            "Epoch [19/20], Step [200/463], Loss: 0.0114\n",
            "Epoch [19/20], Step [300/463], Loss: 0.1194\n",
            "Epoch [19/20], Step [400/463], Loss: 0.0255\n",
            "Epoch [20/20], Step [100/463], Loss: 0.0942\n",
            "Epoch [20/20], Step [200/463], Loss: 0.0000\n",
            "Epoch [20/20], Step [300/463], Loss: 0.0003\n",
            "Epoch [20/20], Step [400/463], Loss: 0.0002\n",
            "Finished Training Trainset\n"
          ]
        }
      ],
      "source": [
        "list_loss = train(network3, optimizer, loss_fn, 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fd_aKEY2Q2vI",
        "outputId": "96538bfd-32fb-432c-db7a-9a5cb07a50ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation\n",
            "Test Accuracy of the model: 83.23930418429713 %\n"
          ]
        }
      ],
      "source": [
        "print(\"Validation\")\n",
        "getAccuracy(network3, validation_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YuJmoZgiQ2vI",
        "outputId": "b1aa29f4-40ab-4aa5-d385-f0c738d3ce9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test\n",
            "Test Accuracy of the model: 83.30152671755725 %\n"
          ]
        }
      ],
      "source": [
        "print(\"Test\")\n",
        "getAccuracy(network3, test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2-zPTuqQ2vI"
      },
      "source": [
        "## Agregando Batch Normalization y Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTLpRJcEQ2vI"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(50)\n",
        "class CNN4(nn.Module):\n",
        "    def __init__(self, num_classes = 4):\n",
        "        super(CNN3, self).__init__()\n",
        "        self.flatten = nn.Flatten() # Reduce cualquier matriz a 1D\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=2),# 256 -> 258 (mask) 299 -> 301\n",
        "            nn.Dropout(p = 0.25),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2), # 129 | 150\n",
        "            nn.BatchNorm2d(16)\n",
        "        )\n",
        "        # Comentar el dropout y batch normalization para el siguiente experimento\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2), # 129 -> 129 (mask) | 150-> 150\n",
        "            nn.Dropout(p = 0.25),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),# 129 // 2 = 64 (mask) | 75\n",
        "            nn.BatchNorm2d(32)\n",
        "        )\n",
        "        self.fc = nn.Linear(75*75*32, num_classes) # 64 * 64 * 32 (mask) | 75 * 75 * 32\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TctP3KTDQ2vJ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.13 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "23eb3f05705f7fd6e94ed1bc5c88309c154cf8df965aa1950a47b1af07d4a986"
      }
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}